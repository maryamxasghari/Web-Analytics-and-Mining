---
title: "CS 688 Hw 6 - Topic Modeling Using LDA"
author: "Maryam Asghari"
date: "3/23/2021"
output: html_notebook
---
Set the directory

```{r}
#getwd()
setwd("/Users/maryamasghari/Desktop/Study/Bu M.S/fall 2021/web Analytics/codes/hw6")
```

Load the package required to read JSON files.

```{r}
library(rjson)
library(jsonlite)
```

Create a function to get the tagfiles from json file 

```{r}

get_data <- function(json_file) {
  raw_data <- jsonlite::stream_in(file(json_file))
  titles <- raw_data[["data"]]["title"]
  taglines<- raw_data[["data"]]["tagline"]
  file_1000 <-data.frame(title = titles[1:1000,],tagline = taglines[1:1000,]) 
  return(file_1000)
}
```


## Importing the data 
### Reading the json files and get titles and taglines from 5 json file 

```{r}
file1 <- get_data("Indiegogo_2017-03-15T21_40_51_862Z.json")
file2 <- get_data("Indiegogo_2018-03-16T10_40_19_065Z.json")
file3 <- get_data("Indiegogo_2019-03-15T10_40_03_647Z.json")
file4 <- get_data("Indiegogo_2020-03-13T10_40_05_347Z.json")
file5 <- get_data("Indiegogo_2021-03-12T20_40_49_646Z.json")
```

```{r}
all <- rbind(file1,file2)
all <- rbind(all,file3)
all <- rbind(all,file4)
all <- rbind(all,file5)

nrow(all)
```


```{r}
file1
```


```{r}
write.csv(all,"/Users/maryamasghari/Desktop/Study/Bu M.S/fall 2021/web Analytics/codes/hw6/files.csv", row.names = FALSE)
```

#Data preprocessing

```{r}
#library('tokenizers')
#library('tm')

clean_corpus <- function(text){
  corpus <- Corpus(VectorSource(text))
  corpus <- tm_map(corpus,removeNumbers)
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removeWords, stopwords("en"))
  return(corpus)
}

cl_corpus <- clean_corpus(all$tagline)
cl_corpus
```

## Create the Document Term Matrix from the corpus

```{r}

dtm <- DocumentTermMatrix(cl_corpus )
dtm

```

Remove the rows that are all zero 

```{r}

#install.packages("quanteda")
#library("quanteda")
df <- as.dfm(dtm)
dtm_notsparce <- dfm_subset(df, ntoken(df) > 0)
dim(dtm_notsparce)

```

```{r}
dtm_notsparce[1:5,1:10]
```

```{r}
dtm_notsparce[4980:4985,11566:11575]
```


```{r}

#install.packages("topicmodels")
library(topicmodels)

```

## Fitting the LDA Model

```{r}
# set a seed so that the output of the model is predictable
lda <- LDA(dtm_notsparce, method = "Gibbs",k = 10,control = list(seed = 1234))
lda

```
```{r}
# set a seed so that the output of the model is predictable
lda15 <- LDA(dtm_notsparce, method = "Gibbs",k = 15,control = list(seed = 1234))
lda15

```

```{r}
str(lda)

```
```{r}
lda@loglikelihood
logLik(lda)
```
```{r}
lda15@loglikelihood
logLik(lda15)
```

## Inspecting LDA results

```{r}
#library(tidytext)
#library(dplyr)
words_prob <- tidy(lda, matrix = "beta")
words_prob
```
#ten top words of each topic 
```{r}
top_terms<- words_prob %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)
top_terms
```
#
```{r}
docs_topics <- tidy(lda, matrix = "gamma")
head(docs_topics) 
```

```{r}
posterior(lda)$topics
```


```{r}
tail(docs_topics)
```
```{r}
docs_topics[order(-docs_topics$gamma),]
```

```{r}
all[542,]
```

```{r}
tag542 = docs_topics[docs_topics$document == 542,]
tag542[order(-tag542$gamma),]

```



```{r}
all[606,]
```
```{r}
tag606 = docs_topics[docs_topics$document == 606,]
tag606[order(-tag606$gamma),]
```

```{r, fig.width = 12, fig.height = 12}
#library(ggplot2)
top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  theme(strip.text.x = element_text(size = 25, color = "red", face = "bold.italic" ))+
  theme(axis.text.x=element_text(size=rel(2)))+
   theme(axis.text.y=element_text(size=rel(2), face = "bold"))+
  ggtitle("Top Ten Words in Each Topic")+
  theme(plot.title = element_text(size=50))+
  scale_y_reordered()
```



```{r}
terms(lda,10)
```

```{r}
library(topicmodels)
```

```{r}
topic = 6
words = posterior(lda)$terms[topic, ]
topwords = head(sort(words, decreasing = T), n=50)
head(topwords)
```


```{r,fig.width = 2, fig.height = 2}
#install.packages("wordcloud")
#library(wordcloud)
wordcloud(names(topwords), topwords,colors="blue",ordered.colors=TRUE)
```

```{r}
topic.docs = posterior(lda)$topics[, topic] 
topic.docs = sort(topic.docs, decreasing=T)
head(topic.docs)
```


```{r}
dfm = as.dfm(dtm)
docs = docvars(dfm)
topdoc = names(topic.docs)[1]
docid = which(rownames(docs) == topdoc)
all$tagline[docid]
```
```{r}
all[c(2080,572,642,996,49,228),]
```


```{r}
lda_matrix = posterior(lda)$topics
```

part of the matrix 
```{r}
sub = lda_matrix[1:500 ,1:10]
```

```{r,fig.width = 4, fig.height = 6}
heatmap(sub)

```

```{r}

sub = lda_matrix[1:10 ,1:10]
sub
```

```{r,fig.width = 3, fig.height = 3}
#install.packages("pheatmap")
library(pheatmap)


pheatmap(sub, display_numbers = T,fontsize_number =10)
```


```{r}
c = cor(posterior(lda)$topics)
#diag(c) = 0
c
```



```{r,fig.width = 3, fig.height =3}

pheatmap(c, display_numbers = T,fontsize_number =10)

```

```{r,fig.width = 3, fig.height =3}
#c = cor(posterior(lda)$topics)
diag(c) = 0
pheatmap(c, display_numbers = T,fontsize_number =10)

```

