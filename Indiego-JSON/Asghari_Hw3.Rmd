---
title: "Hw3"
author: "Maryam Asghari"
date: "2/19/2021"
output:
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1 
Use the Indiegogo dataset (https://webrobots.io/indiegogo-dataset/) and download five files of data, preferable in different years.
1. For each of these categories* in the category of JSON element, check whether all keywords has a gaussian distribution. You should count the appearance of the keyword per month and then assign keyword month. e.g. “Education”, “Jan”, “2020”, “32”
Then, plot their distributions based on the number of year (use density plot in R). It means you should download the data for five years and then compare their frequency each one separately.


```{r include=FALSE}
# Set the directory
getwd()
setwd("/Users/maryamasghari/Desktop/Study/Bu M.S/fall 2021/web Analytics/Assignments/Hw3")
```

 
```{r include=FALSE}
#loading required libraries
# Load the package required to read JSON files.
library(rjson)
library(jsonlite)
# Load the package for q-q plot with lower and upper limit - 95% conf int
library(car)
# Load the package for printing data frames table
#install.packages("formattable")
library(formattable)

#install.packages("effsize")
library("effsize")
```


```{r include=FALSE}
#Create some functions
# Create a function to get the data from json file 
get_data <- function(json_file) {
  raw_data <- jsonlite::stream_in(file(json_file))
  return(raw_data)
}
```

```{r include=FALSE}
#Create a function to get the year and month of each json file 

get_date <-  function(json_read){
  date <- json_read[["run_id"]][1]
  s1 = unlist(strsplit(date, split=c('_'), fixed=TRUE))[2]
  s1 = unlist(strsplit(s1, split=c('T'), fixed=TRUE))[1]
  date <-  as.Date(s1,"%Y-%m-%d")
  year <- as.numeric(format(date,'%Y'))
  month <-  month.abb[as.numeric(format(date, "%m"))]
  return(c(year,month))
}
```


```{r  include=FALSE}
#Create a function to get the frequency of each keyword from each file 
#json files from 2016 and 2017 had different formats
get_freq <- function(json_read,word){
  category <- json_read[["data"]]["category"]
  freq <- length(category[category == word ])
  return (c(word, freq))
}
get_freq2 <- function(data,word){
  category <- data[["data"]]["category_name"]
  freq <- length(category[category == word ])
  return (c(word, freq))
}
```

 
```{r include=FALSE}
#function to add all 4 values to a data frame (same for 2016-2017)

add_data <- function(df,data,date,keyword){
  freq <- get_freq(data,keyword)
  df[nrow(df) + 1,] = c(freq[1],date[1],date[2],freq[2])
  return(df)
}
add_data2 <- function(df,data,date,keyword){
  freq <- get_freq2(data,keyword)
  df[nrow(df) + 1,] = c(freq[1],date[1],date[2],freq[2])
  return(df)
}
```


```{r include=FALSE}

#get a data frame with data from all 5 files for each keyword
keyword_df <- function(df,keyword){
  df <- add_data2(df,data1,date1,keyword)
  df <- add_data2(df,data2,date2,keyword)
  df <- add_data(df,data3,date3,keyword)
  df <- add_data(df,data4,date4,keyword)
  df <- add_data(df,data5,date5,keyword)
  df$freq <- as.numeric(df$freq)
  return(df)
}
```


```{r include=FALSE}
#function to create 4 plots for each keyword and save a jpg file 

plot_dens_hist <- function(df,keyword){
  jpeg(paste(keyword,".jpg"))
  par(mfrow=c(2,2))
  
  hist(df$freq,col = "skyblue",border = FALSE,main ="Histogram", xlab = "Frequency",
       ylab = "Count")

  plot(density(df$freq), frame = FALSE,lwd=2, col = "blue",main = "Density plot" )
 
  plot(density(df$freq,adjust = 10), frame = FALSE,lwd=2, col = "blue",main = "Density plot, adj = 10" ,
       sub = paste(" --- mean = ",mean(df$freq)) )
 
  abline(v=mean(df$freq),lty="dashed")
  
  qqPlot(df$freq , main = " Q-Q plot with lower and upper limit" ,ylab = "Frequency Quantiles")
  
   dev.off()
  }
```
 
```{r include=FALSE}
#Reading the Json files and get the required information
#get the data and date of 5 files
data1 <- get_data("Indiegogo_2016-10-14T04_16_17_051Z.json")
date1 <- get_date(data1)

data2 <- get_data("Indiegogo_2017-07-15T21_40_50_545Z.json")
date2 <- get_date(data2)

data3 <- get_data("Indiegogo_2018-08-17T10_40_24_782Z.json")
date3 <- get_date(data3)

data4 <- get_data("Indiegogo_2019-03-15T10_40_03_647Z.json")
date4 <- get_date(data4)

data5 <- get_data("Indiegogo_2020-04-17T10_40_10_294Z.json")
date5 <- get_date(data5)
```



```{r include=FALSE}
#create an empty data frame
tmp_df <- data.frame(category=character(),
                 year=character(), 
                 month=character(), 
                 freq=integer(),
                 stringsAsFactors=FALSE) 
```



```{r include=FALSE}
#create the data frame for each keyword
df_Edu <- keyword_df(tmp_df ,"Education")
df_ENer <- keyword_df(tmp_df ,"Energy & Green Tech")
df_Heal <- keyword_df(tmp_df ,"Health & Fitness")
df_Fash <- keyword_df(tmp_df ,"Fashion & Wearables")
df_Well <- keyword_df(tmp_df ,"Wellness")

```

Density plot for each keyword 

###Education

```{r echo=FALSE}
df_Edu
```

```{r echo=FALSE}
plot_dens_hist(df_Edu,"Education" )
```

Density plot
```{r echo=FALSE}
plot(density(df_Edu$freq), frame = FALSE,lwd=2, col = "blue",main = "Density plot - Education" )
```

Q-Q plot
```{r echo=FALSE}
qqnorm(df_Edu$freq, pch = 1, frame = FALSE,  xlim = c())
qqline(df_Edu$freq, col = "steelblue", lwd = 2)
```

###Energy & Green Tech

```{r echo=FALSE}
df_ENer
```


```{r echo=FALSE}

plot_dens_hist(df_ENer,"Energy & Green Tech" )

```
Density plot
```{r echo=FALSE}
plot(density(df_ENer$freq), frame = FALSE,lwd=2, col = "blue",main = "Density plot - Energy & Green Tech" )
```

Q-Q plot
```{r echo=FALSE}
qqnorm(df_ENer$freq, pch = 1, frame = FALSE,  xlim = c())
qqline(df_ENer$freq, col = "steelblue", lwd = 2)
```


###Health & Fitness
```{r echo=FALSE}
df_Heal
```


```{r echo=FALSE}
plot_dens_hist(df_Heal,"Health & Fitness")

```

Density plot
```{r echo=FALSE}
plot(density(df_Heal$freq), frame = FALSE,lwd=2, col = "blue",main = "Density plot - Health & Fitness" )
```

Q-Q plot
```{r echo=FALSE}
qqnorm(df_Heal$freq, pch = 1, frame = FALSE,  xlim = c())
qqline(df_Heal$freq, col = "steelblue", lwd = 2)
```

###Fashion & Wearables
```{r echo=FALSE}
df_Fash
```


```{r echo=FALSE}
plot_dens_hist(df_Fash,"Fashion & Wearables")

```

Density plot
```{r echo=FALSE}
plot(density(df_Fash$freq), frame = FALSE,lwd=2, col = "blue",main = "Density plot - Fashion & Wearables" )
```

Q-Q plot
```{r echo=FALSE}
qqnorm(df_Fash$freq, pch = 1, frame = FALSE,  xlim = c())
qqline(df_Fash$freq, col = "steelblue", lwd = 2)
```

###Wellness
```{r echo=FALSE}
df_Well
```


```{r echo=FALSE}
plot_dens_hist(df_Well,"Wellness")

```

Density plot
```{r echo=FALSE}
plot(density(df_Well$freq), frame = FALSE,lwd=2, col = "blue",main = "Density plot - Wellness" )
```

Q-Q plot
```{r echo=FALSE}
qqnorm(df_Well$freq, pch = 1, frame = FALSE,  xlim = c())
qqline(df_Well$freq, col = "steelblue", lwd = 2)
```

##Question 2

Compare following two categories: “Health & Fitness”, “Fashion & Wearables” on year basis (2018, 2019, 2020).

* H0 = Avg frequency of “Health & Fitness” and “Fashion & Wearables” are equal 
* H1 = Avg frequency of “Health & Fitness” and “Fashion & Wearables” are not equal 
* significance level α = 0.05


```{r echo=FALSE}
heal_fash <- merge(df_Heal[3:5,],df_Fash[3:5,],by=c("year","month"))
heal_fash
```
```{r}
mydata <- rbind(df_Heal[3:5,],df_Fash[3:5,])
mydata
```


a) With three statistics tests, one parametric, two non-parametric tests and report results.

```{r}
par(mfrow=c(1,2))

qqnorm(heal_fash$freq.x, pch = 16, frame = FALSE,  xlim = c(),main = "Q-Q Plot-Health")
qqline(heal_fash$freq.x, col = "black", lwd = 2,lty="dashed")

qqnorm(heal_fash$freq.y, pch = 16, frame = FALSE,  xlim = c(),main = "Q-Q Plot-Fashion")
qqline(heal_fash$freq.y, col = "black", lwd = 2,lty="dashed")

```


None of them are following the desired distribution because it is not creating a straight line.

**a -1) One parametric test** 

We assume that all samples have a normal distribution.

Two sample t-test :

1- 2 independent group 

2- SD of the population is unknown 

3- we assume they are noraml 

4- means are different 

```{r}
mean(heal_fash$freq.x)
mean(heal_fash$freq.y)

```

```{r echo=FALSE}
t.test(heal_fash$freq.x , heal_fash$freq.y,alternative="two.sided", conf.level=0.95)
```

P-value = 0.99 
We fail to reject H0, We don't have significant evidance that the mean of these two groups are not equal. There is not a significant differences between two groups.


ANOVA
One-Way ANOVA: In this test we have only one variable (factors) with at least two values (levels) and levels are independent.


The H0 in ANOVA assumes that all groups’ mean are equal
H1 assumes at least two of group means are different.

```{r}

aovres = aov(freq~category,data=mydata) 
summary(aovres)
```
```{r}
boxplot(freq~category,data=mydata)
```

**a-2) Two non-parametric tests**

non-parametric tests do not rely on the normal distribution of samples.

1- Kolmogorov-Smirnov (KS-Test)
It is based on the measuring the differences between Cumulative
Distribution Function (CDF) of two different dataset.


```{r echo=FALSE}
ks.test(heal_fash$freq.x , heal_fash$freq.y)
```
p-value = 0.99

We fail to reject H0, We don't have significant evidance that the mean of these two groups are different

2- Mann-Whitney-Wilcoxon 

H0: The distributions of both samples are equal.

H1: The distributions of both samples are not equal.

```{r echo=FALSE}
wilcox.test(heal_fash$freq.x , heal_fash$freq.y)
```


b. Use the effect size test, to quantify the magnitude of differences.

Significance test does not tell anything about the magnitude or size of the
difference. The effect size tells us about the size of differences between two
groups.

**Cohen's d Test and Cliff delta test**

```{r echo=FALSE}

res1 <- cohen.d(heal_fash$freq.x , heal_fash$freq.y,return.dm=TRUE)
print(res1)
res2 <- cliff.delta(heal_fash$freq.x , heal_fash$freq.y,return.dm=TRUE)
print(res2)
```

# Question 3: 

Use three correlation coefficient tests (Pearson, Spearman, KendallTau) and report whether following two keywords have correlations: “Fashion & Wearables”, “Health & Fitness”.

Correlation co-efficient is a score between -1 to +1, presented as r. This score indicates the linear relations between two variables.
• Pearson
• Kendall
• Spearman

* since it didn't mentioned in the question I will give cor for both 3 years and five years. 

**3 years**
(2018, 2019, 2020)

```{r}
print("Pearson:")
cor(heal_fash$freq.y, heal_fash$freq.x  ,  method = "pearson")
print("Kendall:")
cor(heal_fash$freq.y, heal_fash$freq.x , method = "kendall")
print("Spearman:")
cor(heal_fash$freq.y, heal_fash$freq.x  , method = "spearman")
```

Two variables have positive correlation
Pearson is only able to measure a linear relationship between two variables

Kendall’s Tau correlation, which is similar to Spearman correlation
non-parametric, but usually it returns smaller values than Spearman.

```{r echo=FALSE}
plot(heal_fash$freq.x, heal_fash$freq.y)
abline(lm(heal_fash$freq.x ~ heal_fash$freq.y), col = "blue")

```

**5 years** 

```{r}
heal_fash2 <- merge(df_Heal,df_Fash,by=c("year","month"))
heal_fash2
```

```{r}
print("Pearson:")
cor(heal_fash2$freq.y, heal_fash2$freq.x  ,  method = "pearson")
print("Kendall:")
cor( heal_fash2$freq.y, heal_fash2$freq.x , method = "kendall")
print("Kendall:")
cor(heal_fash2$freq.y,heal_fash2$freq.x  , method = "spearman")
```


```{r echo=FALSE}
plot(heal_fash2$freq.x, heal_fash2$freq.y)
abline(lm(heal_fash2$freq.x ~ heal_fash2$freq.y), col = "blue")
lines(lowess(heal_fash2$freq.x, heal_fash2$freq.y), col = "red")

```
```{r}
simple_fit <- lm(heal_fash2$freq.x ~ heal_fash2$freq.y)
summary(simple_fit)
```






